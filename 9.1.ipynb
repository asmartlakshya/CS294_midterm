{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNr6vaItbpaOQzaHkKLoxtR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n"],"metadata":{"id":"Uzr-D2yLnrvZ","executionInfo":{"status":"ok","timestamp":1711085139718,"user_tz":420,"elapsed":18339,"user":{"displayName":"Lakshya Aggarwal","userId":"08526187129492329316"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["First Model"],"metadata":{"id":"MSgILYit3f4j"}},{"cell_type":"code","source":["# random rotation and horizontal flipping, epochs = 10, and learning rate scheduler to gradually reduce the learning rate during training.\n","\n","\n","from torch.optim.lr_scheduler import StepLR\n","\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(torch.relu(self.conv1(x)))\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        x = x.view(-1, 64 * 7 * 7)\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","\n","transform = transforms.Compose([\n","    transforms.RandomRotation(15),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n","model = CNN()\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Learning rate scheduler\n","scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n","\n","# Train the model\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        inputs, labels = data\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","        if i % 100 == 99:\n","            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n","            running_loss = 0.0\n","    scheduler.step()\n","\n","print('Finished Training')\n","\n","# Evaluate the model\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        inputs, labels = data\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %.2f %%' % (100 * correct / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DyT1drUjntgD","executionInfo":{"status":"ok","timestamp":1711087287159,"user_tz":420,"elapsed":1164707,"user":{"displayName":"Lakshya Aggarwal","userId":"08526187129492329316"}},"outputId":"65344daa-c0c1-46c0-bc04-5e576b4ef4c9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[1,   100] loss: 1.043\n","[1,   200] loss: 0.441\n","[1,   300] loss: 0.390\n","[1,   400] loss: 0.280\n","[1,   500] loss: 0.258\n","[1,   600] loss: 0.224\n","[1,   700] loss: 0.186\n","[1,   800] loss: 0.173\n","[1,   900] loss: 0.155\n","[2,   100] loss: 0.132\n","[2,   200] loss: 0.116\n","[2,   300] loss: 0.118\n","[2,   400] loss: 0.121\n","[2,   500] loss: 0.116\n","[2,   600] loss: 0.111\n","[2,   700] loss: 0.110\n","[2,   800] loss: 0.109\n","[2,   900] loss: 0.114\n","[3,   100] loss: 0.111\n","[3,   200] loss: 0.101\n","[3,   300] loss: 0.103\n","[3,   400] loss: 0.100\n","[3,   500] loss: 0.112\n","[3,   600] loss: 0.097\n","[3,   700] loss: 0.109\n","[3,   800] loss: 0.103\n","[3,   900] loss: 0.102\n","[4,   100] loss: 0.111\n","[4,   200] loss: 0.096\n","[4,   300] loss: 0.109\n","[4,   400] loss: 0.093\n","[4,   500] loss: 0.091\n","[4,   600] loss: 0.102\n","[4,   700] loss: 0.109\n","[4,   800] loss: 0.109\n","[4,   900] loss: 0.105\n","[5,   100] loss: 0.116\n","[5,   200] loss: 0.100\n","[5,   300] loss: 0.105\n","[5,   400] loss: 0.106\n","[5,   500] loss: 0.100\n","[5,   600] loss: 0.100\n","[5,   700] loss: 0.104\n","[5,   800] loss: 0.102\n","[5,   900] loss: 0.092\n","[6,   100] loss: 0.104\n","[6,   200] loss: 0.093\n","[6,   300] loss: 0.115\n","[6,   400] loss: 0.097\n","[6,   500] loss: 0.097\n","[6,   600] loss: 0.096\n","[6,   700] loss: 0.101\n","[6,   800] loss: 0.105\n","[6,   900] loss: 0.113\n","[7,   100] loss: 0.099\n","[7,   200] loss: 0.109\n","[7,   300] loss: 0.106\n","[7,   400] loss: 0.087\n","[7,   500] loss: 0.107\n","[7,   600] loss: 0.107\n","[7,   700] loss: 0.101\n","[7,   800] loss: 0.106\n","[7,   900] loss: 0.095\n","[8,   100] loss: 0.094\n","[8,   200] loss: 0.105\n","[8,   300] loss: 0.108\n","[8,   400] loss: 0.107\n","[8,   500] loss: 0.105\n","[8,   600] loss: 0.101\n","[8,   700] loss: 0.100\n","[8,   800] loss: 0.099\n","[8,   900] loss: 0.101\n","[9,   100] loss: 0.099\n","[9,   200] loss: 0.105\n","[9,   300] loss: 0.102\n","[9,   400] loss: 0.114\n","[9,   500] loss: 0.105\n","[9,   600] loss: 0.098\n","[9,   700] loss: 0.100\n","[9,   800] loss: 0.101\n","[9,   900] loss: 0.099\n","[10,   100] loss: 0.101\n","[10,   200] loss: 0.095\n","[10,   300] loss: 0.109\n","[10,   400] loss: 0.110\n","[10,   500] loss: 0.097\n","[10,   600] loss: 0.092\n","[10,   700] loss: 0.103\n","[10,   800] loss: 0.102\n","[10,   900] loss: 0.103\n","Finished Training\n","Accuracy of the network on the 10000 test images: 96.75 %\n"]}]},{"cell_type":"code","source":["# Calculate total number of parameters\n","total_params = sum(p.numel() for p in model.parameters())\n","\n","# Define input dimensions\n","input_dim = (1, 28, 28)\n","\n","# Calculate compression ratio of the original dataset\n","t_size = np.prod(input_dim)\n","compression_ratio = total_params / t_size\n","print(\"The original dataset compression ratio is:\", compression_ratio)\n","\n","# Calculate compression ratio after the last layer\n","output_size = np.prod(model.fc2.out_features)  # Assuming model.fc2 is the last fully connected layer\n","compression_ratio_last_layer = output_size / t_size\n","print(\"The original dataset compression ratio after the last layer:\", compression_ratio_last_layer)\n","\n","# Calculate compression ratios for convolutional layers\n","compression_layer_ratios = []\n","for name, param in model.named_parameters():\n","    if 'conv' in name:\n","        input_size = np.prod(param.shape[1:])\n","        output_size = np.prod(param.shape[:2]) * np.prod(param.shape[3:])\n","        compression_ratio_layer = output_size / input_size\n","        compression_layer_ratios.append(compression_ratio_layer)\n","\n","print(\"Compression ratios for convolutional layers:\", compression_layer_ratios)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wm5Sexua0Nu8","executionInfo":{"status":"ok","timestamp":1711088930170,"user_tz":420,"elapsed":215,"user":{"displayName":"Lakshya Aggarwal","userId":"08526187129492329316"}},"outputId":"001d86f4-b20a-4bda-da6a-0e0d9101f9c7"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["The original dataset compression ratio is: 537.8086734693877\n","The original dataset compression ratio after the last layer: 0.012755102040816327\n","Compression ratios for convolutional layers: [10.666666666666666, 32.0, 21.333333333333332, 64.0]\n"]}]},{"cell_type":"markdown","source":["2nd Model"],"metadata":{"id":"SiR5u-753k3h"}},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KQb6rGQ2X7Po","executionInfo":{"status":"ok","timestamp":1711089749183,"user_tz":420,"elapsed":513146,"user":{"displayName":"Lakshya Aggarwal","userId":"08526187129492329316"}},"outputId":"7810fca4-a34d-4d5d-b9e7-4c692fe0e76d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1,   100] loss: 0.774\n","[1,   200] loss: 0.189\n","[1,   300] loss: 0.123\n","[1,   400] loss: 0.107\n","[1,   500] loss: 0.098\n","[1,   600] loss: 0.080\n","[1,   700] loss: 0.080\n","[1,   800] loss: 0.072\n","[1,   900] loss: 0.057\n","[2,   100] loss: 0.048\n","[2,   200] loss: 0.050\n","[2,   300] loss: 0.049\n","[2,   400] loss: 0.044\n","[2,   500] loss: 0.046\n","[2,   600] loss: 0.046\n","[2,   700] loss: 0.048\n","[2,   800] loss: 0.053\n","[2,   900] loss: 0.047\n","[3,   100] loss: 0.035\n","[3,   200] loss: 0.029\n","[3,   300] loss: 0.034\n","[3,   400] loss: 0.030\n","[3,   500] loss: 0.030\n","[3,   600] loss: 0.037\n","[3,   700] loss: 0.029\n","[3,   800] loss: 0.031\n","[3,   900] loss: 0.032\n","[4,   100] loss: 0.023\n","[4,   200] loss: 0.022\n","[4,   300] loss: 0.024\n","[4,   400] loss: 0.019\n","[4,   500] loss: 0.026\n","[4,   600] loss: 0.020\n","[4,   700] loss: 0.034\n","[4,   800] loss: 0.022\n","[4,   900] loss: 0.019\n","[5,   100] loss: 0.018\n","[5,   200] loss: 0.019\n","[5,   300] loss: 0.020\n","[5,   400] loss: 0.017\n","[5,   500] loss: 0.014\n","[5,   600] loss: 0.015\n","[5,   700] loss: 0.024\n","[5,   800] loss: 0.015\n","[5,   900] loss: 0.021\n","Finished Training\n","Accuracy of the network on the 10000 test images: 98.76 %\n"]}],"source":["# Define custom CNN architecture\n","# CNN with two convolutional layers and two fully connected layers.\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(torch.relu(self.conv1(x)))\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        x = x.view(-1, 64 * 7 * 7)\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Load the MNIST dataset\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n","\n","# Initialize the model, loss function, and optimizer\n","model = CNN()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Train the model\n","num_epochs = 5\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        inputs, labels = data\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","        if i % 100 == 99:\n","            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n","            running_loss = 0.0\n","\n","print('Finished Training')\n","\n","# Evaluate the model\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        inputs, labels = data\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: %.2f %%' % (100 * correct / total))"]},{"cell_type":"code","source":["# Define input dimensions\n","input_dim = (1, 28, 28)\n","\n","# Calculate compression ratio of the original dataset\n","t_size = np.prod(input_dim)\n","compression_ratio = total_params / t_size\n","print(\"The original dataset compression ratio is:\", compression_ratio)\n","\n","# Calculate compression ratio after the last layer\n","output_size = np.prod(model.fc2.out_features)  # Assuming model.fc2 is the last fully connected layer\n","compression_ratio_last_layer = output_size / t_size\n","print(\"The original dataset compression ratio after the last layer:\", compression_ratio_last_layer)\n","\n","# Calculate compression ratios for convolutional layers\n","compression_layer_ratios = []\n","for name, param in model.named_parameters():\n","    if 'conv' in name:\n","        input_size = np.prod(param.shape[1:])\n","        output_size = np.prod(param.shape[:2]) * np.prod(param.shape[3:])\n","        compression_ratio_layer = output_size / input_size\n","        compression_layer_ratios.append(compression_ratio_layer)\n","\n","print(\"Compression ratios for convolutional layers:\", compression_layer_ratios)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qESzpKZg3UhT","executionInfo":{"status":"ok","timestamp":1711089749183,"user_tz":420,"elapsed":23,"user":{"displayName":"Lakshya Aggarwal","userId":"08526187129492329316"}},"outputId":"df035314-e245-435b-b2b9-25f242ff6f28"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["The original dataset compression ratio is: 537.8086734693877\n","The original dataset compression ratio after the last layer: 0.012755102040816327\n","Compression ratios for convolutional layers: [10.666666666666666, 32.0, 21.333333333333332, 64.0]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"F2GrqCEf2Qn1"},"execution_count":null,"outputs":[]}]}